{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sWxDDkRwLVMC"
   },
   "source": [
    "# Transfer learning for video engagement classification with MoViNet\n",
    "\n",
    "This notebook is forked from Tensorflow implementation of transfer learning on MoViNets (Mobile Video Networks), which is a family of efficient video classification models, supporting inference on streaming video. You can check the official tutorial on [MoViNet for streaming action recognition](https://www.tensorflow.org/hub/tutorials/movinet)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:20:44.186429Z",
     "iopub.status.busy": "2022-12-19T02:20:44.185832Z",
     "iopub.status.idle": "2022-12-19T02:21:13.696456Z",
     "shell.execute_reply": "2022-12-19T02:21:13.695584Z"
    },
    "id": "nubWhqYdwEXD"
   },
   "outputs": [],
   "source": [
    "#!pip install remotezip tqdm opencv-python==4.5.2.52 opencv-python-headless==4.5.2.52 tf-models-official\n",
    "#!pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:21:13.700788Z",
     "iopub.status.busy": "2022-12-19T02:21:13.700507Z",
     "iopub.status.idle": "2022-12-19T02:21:17.118005Z",
     "shell.execute_reply": "2022-12-19T02:21:17.117075Z"
    },
    "id": "QImPsudoK9JI"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import imageio\n",
    "import os\n",
    "from glob import glob1\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# Import the MoViNet model from TensorFlow Models (tf-models-official) for the MoViNet model\n",
    "from official.projects.movinet.modeling import movinet\n",
    "from official.projects.movinet.modeling import movinet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 10 13:42:15 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:3E:00.0 Off |                    0 |\r\n",
      "| N/A   26C    P0    51W / 300W |  31928MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     77977      C   ...aconda/2022.05/bin/python    31925MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2w3H4dfOPfnm"
   },
   "source": [
    "## Load data\n",
    "\n",
    "If you already downloaded our engagement dataset, create 10-sec clips from the videos using the [../data-pipeline/slice_based_on_levels.ipynb](../data-pipeline/slice_based_on_levels.ipynb). The following cell will then create a train/test split automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nengagement_levels = [\"-2\", \"-1\", \"0\", \"1\", \"2\"]\\n!mkdir ../engagement-slices/movinet_dataset\\nfor e in engagement_levels:\\n    !mkdir {\"../engagement-slices/movinet_dataset/%s\" % e}\\n\\nfor i in range(4,9):\\n    for e in engagement_levels:\\n        for v in glob1(\"../engagement-slices/%d/%s\" % (i, e),\"*.mp4\"):\\n            print(v)\\n            !cp {\"../engagement-slices/%d/%s/%s\" % (i, e, v)} {\"../engagement-slices/movinet_dataset/%s\" % e}\\n            \\nimport splitfolders\\nsplitfolders.ratio(\\'../engagement-slices/movinet_dataset\\', output=\"output\", seed=1337, ratio=(0.8, 0.2)) \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Dataset in FrameGenerator Format\n",
    "\n",
    "\"\"\"\n",
    "engagement_levels = [\"-2\", \"-1\", \"0\", \"1\", \"2\"]\n",
    "!mkdir ../engagement-slices/movinet_dataset\n",
    "for e in engagement_levels:\n",
    "    !mkdir {\"../engagement-slices/movinet_dataset/%s\" % e}\n",
    "\n",
    "for i in range(4,9):\n",
    "    for e in engagement_levels:\n",
    "        for v in glob1(\"../engagement-slices/%d/%s\" % (i, e),\"*.mp4\"):\n",
    "            print(v)\n",
    "            !cp {\"../engagement-slices/%d/%s/%s\" % (i, e, v)} {\"../engagement-slices/movinet_dataset/%s\" % e}\n",
    "            \n",
    "import splitfolders\n",
    "splitfolders.ratio('../engagement-slices/movinet_dataset', output=\"output\", seed=1337, ratio=(0.8, 0.2)) \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_frames(frame, output_size):\n",
    "  \"\"\"\n",
    "    Pad and resize an image from a video.\n",
    "\n",
    "    Args:\n",
    "      frame: Image that needs to resized and padded. \n",
    "      output_size: Pixel size of the output frame image.\n",
    "\n",
    "    Return:\n",
    "      Formatted frame with padding of specified output size.\n",
    "  \"\"\"\n",
    "  frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
    "  frame = tf.image.resize_with_pad(frame, *output_size)\n",
    "  return frame\n",
    "\n",
    "def frames_from_video_file(video_path, n_frames, output_size = (224,224)):\n",
    "  \"\"\"\n",
    "    Creates frames from each video file present for each category.\n",
    "\n",
    "    Args:\n",
    "      video_path: File path to the video.\n",
    "      n_frames: Number of frames to be created per video file.\n",
    "      output_size: Pixel size of the output frame image.\n",
    "\n",
    "    Return:\n",
    "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
    "  \"\"\"\n",
    "  # Read each video frame by frame\n",
    "  result = []\n",
    "  src = cv2.VideoCapture(str(video_path))  \n",
    "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "  src.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "  # ret is a boolean indicating whether read was successful, frame is the image itself\n",
    "  ret, frame = src.read()\n",
    "  result.append(format_frames(frame, output_size))\n",
    "\n",
    "  for _ in range(n_frames - 1):\n",
    "    for _ in range(12):\n",
    "      ret, frame = src.read()\n",
    "    if ret:\n",
    "      frame = format_frames(frame, output_size)\n",
    "      result.append(frame)\n",
    "    else:\n",
    "      result.append(np.zeros_like(result[0]))\n",
    "  src.release()\n",
    "  result = np.array(result)[..., [2, 1, 0]]\n",
    "\n",
    "  return result\n",
    "\n",
    "class FrameGenerator:\n",
    "  def __init__(self, path, n_frames, training = False):\n",
    "    \"\"\" Returns a set of frames with their associated label. \n",
    "\n",
    "      Args:\n",
    "        path: Video file paths.\n",
    "        n_frames: Number of frames. \n",
    "        training: Boolean to determine if training dataset is being created.\n",
    "    \"\"\"\n",
    "    self.path = path\n",
    "    self.n_frames = n_frames\n",
    "    self.training = training\n",
    "    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
    "    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
    "\n",
    "  def get_files_and_class_names(self):\n",
    "    video_paths = list(self.path.glob('*/*.mp4'))\n",
    "    classes = [p.parent.name for p in video_paths] \n",
    "    return video_paths, classes\n",
    "\n",
    "  def __call__(self):\n",
    "    video_paths, classes = self.get_files_and_class_names()\n",
    "\n",
    "    pairs = list(zip(video_paths, classes))\n",
    "\n",
    "    if self.training:\n",
    "      random.shuffle(pairs)\n",
    "\n",
    "    for path, name in pairs:\n",
    "      video_frames = frames_from_video_file(path, self.n_frames) \n",
    "      label = self.class_ids_for_name[name] # Encode labels\n",
    "      yield video_frames, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYYShfhMx9DW"
   },
   "source": [
    "Create the training and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:22:03.547125Z",
     "iopub.status.busy": "2022-12-19T02:22:03.546861Z",
     "iopub.status.idle": "2022-12-19T02:22:06.910348Z",
     "shell.execute_reply": "2022-12-19T02:22:06.909478Z"
    },
    "id": "-twTu3_Bx-iJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "num_frames = 10\n",
    "\n",
    "output_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
    "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(FrameGenerator(Path(\"./output/train\"), num_frames, training = True),\n",
    "                                          output_signature = output_signature)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(FrameGenerator(Path(\"./output/val\"), num_frames),\n",
    "                                         output_signature = output_signature)\n",
    "test_ds = test_ds.batch(batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "d7stgmuBCGQT"
   },
   "source": [
    "The labels generated here represent the encoding of the classes. For instance, 'Highly Disengaged' is mapped to the integer 0. Take a look at the labels of the training data to ensure that the dataset has been sufficiently shuffled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:22:06.914183Z",
     "iopub.status.busy": "2022-12-19T02:22:06.913913Z",
     "iopub.status.idle": "2022-12-19T02:22:14.836650Z",
     "shell.execute_reply": "2022-12-19T02:22:14.835764Z"
    },
    "id": "k9L2-toXCOQq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 0 1 2 0 0 4 4 1 1 0 4 0 2 4 4 2 2 4 1], shape=(20,), dtype=int16)\n",
      "tf.Tensor([4 0 4 1 1 2 1 4 4 4 4 4 4 0 4 3 0 0 4 2], shape=(20,), dtype=int16)\n",
      "tf.Tensor([0 4 2 4 2 4 2 4 0 4 0 4 4 4 1 0 2 0 4 4], shape=(20,), dtype=int16)\n",
      "tf.Tensor([0 4 4 0 4 4 4 4 0 0 4 4 4 4 2 4 0 4 3 1], shape=(20,), dtype=int16)\n",
      "tf.Tensor([1 0 4 4 0 2 2 0 1 4 0 0 4 2 4 0 4 0 4 4], shape=(20,), dtype=int16)\n",
      "tf.Tensor([4 0 0 1 2 4 4 0 2 0 0 2 2 4 4 0 1 4 2 2], shape=(20,), dtype=int16)\n",
      "tf.Tensor([4 4 2 4 0 0 0 0 4 0 4 4 0 1 0 0 0 0 4 0], shape=(20,), dtype=int16)\n",
      "tf.Tensor([2 0 1 4 4 0 2 2 4 1 0 4 4 4 0 1 0 1 2 0], shape=(20,), dtype=int16)\n",
      "tf.Tensor([2 4 2 4 4 0 1 4 1 4 4 2 2 0 4 1 0 4 4 2], shape=(20,), dtype=int16)\n",
      "tf.Tensor([2 4 0 0 4 0 0 1 2 1 4 4 1 0 1 4 4 4 1 4], shape=(20,), dtype=int16)\n"
     ]
    }
   ],
   "source": [
    "for frames, labels in train_ds.take(10):\n",
    "  print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZ3qwZnpfy9c"
   },
   "source": [
    "Take a look at the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:22:14.840672Z",
     "iopub.status.busy": "2022-12-19T02:22:14.839981Z",
     "iopub.status.idle": "2022-12-19T02:22:14.844416Z",
     "shell.execute_reply": "2022-12-19T02:22:14.843670Z"
    },
    "id": "b6MqP4m2fyQT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (20, 10, 224, 224, 3)\n",
      "Label: (20,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape: {frames.shape}\")\n",
    "print(f\"Label: {labels.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lxbhPqXGvc_F"
   },
   "source": [
    "The MoViNet architecture uses 3D convolutions that are \"causal\" along the time axis (like `layers.Conv1D` with `padding=\"causal\"`). This gives some of the advantages of both approaches, mainly it allow for efficient streaming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:22:14.848014Z",
     "iopub.status.busy": "2022-12-19T02:22:14.847563Z",
     "iopub.status.idle": "2022-12-19T02:22:17.279262Z",
     "shell.execute_reply": "2022-12-19T02:22:17.278358Z"
    },
    "id": "dMvDkgfFZC6a"
   },
   "outputs": [],
   "source": [
    "gru = layers.GRU(units=4, return_sequences=True, return_state=True)\n",
    "\n",
    "inputs = tf.random.normal(shape=[1, 10, 8]) # (batch, sequence, channels)\n",
    "\n",
    "result, state = gru(inputs) # Run it all at once"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "T7xyb5C4bTs7"
   },
   "source": [
    "By setting the RNN's `return_sequences=True` argument we ask it to return the state at the end of the computation. This allows us to pause and then continue where you left off, to get exactly the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:22:17.283472Z",
     "iopub.status.busy": "2022-12-19T02:22:17.283175Z",
     "iopub.status.idle": "2022-12-19T02:22:17.302130Z",
     "shell.execute_reply": "2022-12-19T02:22:17.301138Z"
    },
    "id": "bI8FOPRRXXPa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "first_half, state = gru(inputs[:, :5, :])   # run the first half, and capture the state\n",
    "second_half, _ = gru(inputs[:,5:, :], initial_state=state)  # Use the state to continue where you left off.\n",
    "\n",
    "print(np.allclose(result[:, :5,:], first_half))\n",
    "print(np.allclose(result[:, 5:,:], second_half))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KM3MArumY_Qk"
   },
   "source": [
    "Causal convolutions can be used the same way, if handled with care. This technique was used in the [Fast Wavenet Generation Algorithm](https://arxiv.org/abs/1611.09482) by Le Paine et al. In the [MoVinet paper](https://arxiv.org/abs/2103.11511), the `state` is referred to as the \"Stream Buffer\". By passing this little bit of state forward, we can avoid recalculating the whole receptive field. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "1UsxiPs8yA2e"
   },
   "source": [
    "## Download a pre-trained MoViNet model\n",
    "\n",
    "- Load the pretrained weights. \n",
    "- Freeze the convolutional base, or all other layers except the final classifier head, to speed up fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:22:17.305616Z",
     "iopub.status.busy": "2022-12-19T02:22:17.305032Z",
     "iopub.status.idle": "2022-12-19T02:22:23.870703Z",
     "shell.execute_reply": "2022-12-19T02:22:23.869896Z"
    },
    "id": "rhSCM6cee05F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movinet_a4_base/\n",
      "movinet_a4_base/checkpoint\n",
      "movinet_a4_base/ckpt-1.data-00000-of-00001\n",
      "movinet_a4_base/ckpt-1.index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2b27cc0f56a0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = 'a0'\n",
    "resolution = 224\n",
    "#model_id = 'a4'\n",
    "#resolution = 290\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "backbone = movinet.Movinet(model_id=model_id)\n",
    "backbone.trainable = False\n",
    "\n",
    "# Set num_classes=600 to load the pre-trained weights from the original model\n",
    "model = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600)\n",
    "model.build([None, None, None, None, 3])\n",
    "\n",
    "# Load pre-trained weights\n",
    "#!wget https://storage.googleapis.com/tf_model_garden/vision/movinet/movinet_a0_base.tar.gz -O movinet_a0_base.tar.gz -q\n",
    "#!tar -xvf movinet_a0_base.tar.gz\n",
    "\n",
    "!wget https://storage.googleapis.com/tf_model_garden/vision/movinet/movinet_a4_base.tar.gz -O movinet_a4_base.tar.gz -q\n",
    "!tar -xvf movinet_a4_base.tar.gz\n",
    "\n",
    "checkpoint_dir = f'movinet_{model_id}_base'\n",
    "checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "status = checkpoint.restore(checkpoint_path)\n",
    "status.assert_existing_objects_matched()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BW23HVNtCXff"
   },
   "source": [
    "To build a classifier, create a function that takes the backbone and the number of classes in a dataset. The `build_classifier` function will take the backbone and the number of classes in a dataset to build the classifier. In this case, the new classifier will take a `num_classes` outputs (10 classes for this subset of UCF101)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:22:23.874412Z",
     "iopub.status.busy": "2022-12-19T02:22:23.874145Z",
     "iopub.status.idle": "2022-12-19T02:22:23.878355Z",
     "shell.execute_reply": "2022-12-19T02:22:23.877769Z"
    },
    "id": "6cfAelbU5Gi3"
   },
   "outputs": [],
   "source": [
    "def build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n",
    "  \"\"\"Builds a classifier on top of a backbone model.\"\"\"\n",
    "  model = movinet_model.MovinetClassifier(\n",
    "      backbone=backbone,\n",
    "      num_classes=num_classes)\n",
    "  model.build([batch_size, num_frames, resolution, resolution, 3])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:22:23.881475Z",
     "iopub.status.busy": "2022-12-19T02:22:23.881212Z",
     "iopub.status.idle": "2022-12-19T02:22:25.724414Z",
     "shell.execute_reply": "2022-12-19T02:22:25.723717Z"
    },
    "id": "9HWSk-u7oPUZ"
   },
   "outputs": [],
   "source": [
    "model = build_classifier(batch_size, num_frames, resolution, backbone, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhbX7qdTN8lc"
   },
   "source": [
    "For this tutorial, choose the `tf.keras.optimizers.Adam` optimizer and the `tf.keras.losses.SparseCategoricalCrossentropy` loss function. Use the metrics argument to the view the accuracy of the model performance at every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:22:25.728733Z",
     "iopub.status.busy": "2022-12-19T02:22:25.728241Z",
     "iopub.status.idle": "2022-12-19T02:22:25.746359Z",
     "shell.execute_reply": "2022-12-19T02:22:25.745702Z"
    },
    "id": "dVqBLrn1tBsd"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "model.compile(loss=loss_obj, optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VflEr_t6CuQu"
   },
   "source": [
    "Train the model. After two epochs, observe a low loss with high accuracy for both the training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "execution": {
     "iopub.execute_input": "2022-12-19T02:22:25.749730Z",
     "iopub.status.busy": "2022-12-19T02:22:25.749168Z",
     "iopub.status.idle": "2022-12-19T02:24:28.660059Z",
     "shell.execute_reply": "2022-12-19T02:24:28.659358Z"
    },
    "id": "9ZeiYzI0tqQG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 13:44:54.214907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 24 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 8 input_feature_map_count: 24 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:44:54.732441: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 8 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 24 input_feature_map_count: 8 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:44:57.162908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 80 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 24 input_feature_map_count: 80 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:44:57.690009: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 24 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 80 input_feature_map_count: 24 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:45:01.904553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 184 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 48 input_feature_map_count: 184 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:45:02.538611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 48 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 184 input_feature_map_count: 48 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:45:04.581413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 112 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 32 input_feature_map_count: 112 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:45:05.097849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 32 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 112 input_feature_map_count: 32 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:45:09.702087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 384 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 96 input_feature_map_count: 384 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:45:10.156291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 96 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 384 input_feature_map_count: 96 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:45:12.240159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 280 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 72 input_feature_map_count: 280 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:45:12.717623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 72 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 280 input_feature_map_count: 72 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:45:14.969812: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 344 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 88 input_feature_map_count: 344 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:45:15.315260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 88 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 344 input_feature_map_count: 88 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 13:45:16.659145: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 20 feature_map_count: 480 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 2048 input_feature_map_count: 480 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     92/Unknown - 1050s 11s/step - loss: 1.2511 - accuracy: 0.4571"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 14:02:12.119418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 24 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 8 input_feature_map_count: 24 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:12.136650: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 8 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 24 input_feature_map_count: 8 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:13.776895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 80 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 24 input_feature_map_count: 80 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:13.793219: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 24 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 80 input_feature_map_count: 24 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:16.679556: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 184 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 48 input_feature_map_count: 184 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:16.707349: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 48 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 184 input_feature_map_count: 48 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:18.077574: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 112 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 32 input_feature_map_count: 112 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:18.093619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 32 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 112 input_feature_map_count: 32 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:21.857164: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 384 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 96 input_feature_map_count: 384 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:21.882358: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 96 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 384 input_feature_map_count: 96 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:23.272889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 280 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 72 input_feature_map_count: 280 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:23.294721: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 72 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 280 input_feature_map_count: 72 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:24.738843: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 344 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 88 input_feature_map_count: 344 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:24.754739: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 88 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 344 input_feature_map_count: 88 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:02:25.684717: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 15 feature_map_count: 480 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 2048 input_feature_map_count: 480 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "     93/Unknown - 1075s 11s/step - loss: 1.2498 - accuracy: 0.4582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 14:06:49.742400: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 24 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 8 input_feature_map_count: 24 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:06:49.758476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 8 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 24 input_feature_map_count: 8 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:06:51.274147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 80 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 24 input_feature_map_count: 80 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:06:51.295935: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 24 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 80 input_feature_map_count: 24 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:06:54.082723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 184 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 48 input_feature_map_count: 184 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:06:54.106257: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 48 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 184 input_feature_map_count: 48 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:06:55.510669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 112 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 32 input_feature_map_count: 112 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:06:55.531352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 32 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 112 input_feature_map_count: 32 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:06:59.146633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 384 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 96 input_feature_map_count: 384 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:06:59.170758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 96 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 384 input_feature_map_count: 96 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:07:00.543593: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 280 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 72 input_feature_map_count: 280 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:07:00.564627: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 72 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 280 input_feature_map_count: 72 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:07:02.161392: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 344 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 88 input_feature_map_count: 344 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n",
      "2023-02-10 14:07:02.177171: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 88 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 344 input_feature_map_count: 88 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 1352s 14s/step - loss: 1.2498 - accuracy: 0.4582 - val_loss: 1.0636 - val_accuracy: 0.5570\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 14:07:03.070294: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:5340] Disabling cuDNN frontend for the following convolution:\n",
      "  input: {count: 5 feature_map_count: 480 spatial: 1 1 1  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\n",
      "  filter: {output_feature_map_count: 2048 input_feature_map_count: 480 layout: OutputInputYX shape: 1 1 1 }\n",
      "  {zero_padding: 0 0 0  pad_alignment: default filter_strides: 1 1 1  dilation_rates: 1 1 1 }\n",
      "  ... because it uses an identity activation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 1291s 14s/step - loss: 1.0162 - accuracy: 0.5585 - val_loss: 1.0143 - val_accuracy: 0.5634\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 1291s 14s/step - loss: 0.9130 - accuracy: 0.6156 - val_loss: 1.1487 - val_accuracy: 0.4624\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 1289s 14s/step - loss: 0.8883 - accuracy: 0.6146 - val_loss: 0.9275 - val_accuracy: 0.6086\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 1292s 14s/step - loss: 0.8291 - accuracy: 0.6464 - val_loss: 0.9705 - val_accuracy: 0.6065\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 1292s 14s/step - loss: 0.7620 - accuracy: 0.6814 - val_loss: 0.9264 - val_accuracy: 0.6215\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 1291s 14s/step - loss: 0.7307 - accuracy: 0.6981 - val_loss: 0.8696 - val_accuracy: 0.6473\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 1294s 14s/step - loss: 0.6854 - accuracy: 0.7164 - val_loss: 0.8632 - val_accuracy: 0.6602\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 1291s 14s/step - loss: 0.6584 - accuracy: 0.7439 - val_loss: 0.9272 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 1292s 14s/step - loss: 0.6430 - accuracy: 0.7412 - val_loss: 0.9466 - val_accuracy: 0.5806\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 1293s 14s/step - loss: 0.6213 - accuracy: 0.7547 - val_loss: 1.0264 - val_accuracy: 0.5699\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 1294s 14s/step - loss: 0.6020 - accuracy: 0.7504 - val_loss: 0.9350 - val_accuracy: 0.6086\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 1294s 14s/step - loss: 0.5941 - accuracy: 0.7628 - val_loss: 0.8903 - val_accuracy: 0.6516\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 1292s 14s/step - loss: 0.5667 - accuracy: 0.7725 - val_loss: 0.9263 - val_accuracy: 0.6409\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 1292s 14s/step - loss: 0.5272 - accuracy: 0.7903 - val_loss: 1.0031 - val_accuracy: 0.6430\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 1293s 14s/step - loss: 0.5030 - accuracy: 0.8075 - val_loss: 0.9534 - val_accuracy: 0.6473\n",
      "Epoch 17/20\n",
      "93/93 [==============================] - 1289s 14s/step - loss: 0.5107 - accuracy: 0.7930 - val_loss: 0.9324 - val_accuracy: 0.6366\n",
      "Epoch 18/20\n",
      "93/93 [==============================] - 1291s 14s/step - loss: 0.4826 - accuracy: 0.8102 - val_loss: 0.9186 - val_accuracy: 0.6452\n",
      "Epoch 19/20\n",
      "93/93 [==============================] - 1288s 14s/step - loss: 0.4545 - accuracy: 0.8221 - val_loss: 0.9276 - val_accuracy: 0.6774\n",
      "Epoch 20/20\n",
      "93/93 [==============================] - 1288s 14s/step - loss: 0.4444 - accuracy: 0.8216 - val_loss: 0.9431 - val_accuracy: 0.6344\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(train_ds,\n",
    "                    validation_data=test_ds,\n",
    "                    epochs=num_epochs,\n",
    "                    validation_freq=1,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkLl2zF8G9W0"
   },
   "source": [
    "## Evaluate the model\n",
    "\n",
    "The model achieved high accuracy on the training dataset. Next, use Keras `Model.evaluate` to evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:24:28.664404Z",
     "iopub.status.busy": "2022-12-19T02:24:28.663733Z",
     "iopub.status.idle": "2022-12-19T02:24:47.835259Z",
     "shell.execute_reply": "2022-12-19T02:24:47.834532Z"
    },
    "id": "NqgbzOiKuxxT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 260s 11s/step - loss: 0.9431 - accuracy: 0.6344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.943095862865448, 'accuracy': 0.6344085931777954}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_ds, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkFst2gsHBwD"
   },
   "source": [
    "To visualize model performance further, use a [confusion matrix](https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix). The confusion matrix allows you to assess the performance of the classification model beyond accuracy. To build the confusion matrix for this multi-class classification problem, get the actual values in the test set and the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:24:47.838959Z",
     "iopub.status.busy": "2022-12-19T02:24:47.838314Z",
     "iopub.status.idle": "2022-12-19T02:24:47.842761Z",
     "shell.execute_reply": "2022-12-19T02:24:47.842057Z"
    },
    "id": "hssSdW9XHF_j"
   },
   "outputs": [],
   "source": [
    "def get_actual_predicted_labels(dataset):\n",
    "  \"\"\"\n",
    "    Create a list of actual ground truth values and the predictions from the model.\n",
    "\n",
    "    Args:\n",
    "      dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n",
    "\n",
    "    Return:\n",
    "      Ground truth and predicted values for a particular dataset.\n",
    "  \"\"\"\n",
    "  actual = [labels for _, labels in dataset.unbatch()]\n",
    "  predicted = model.predict(dataset)\n",
    "\n",
    "  actual = tf.stack(actual, axis=0)\n",
    "  predicted = tf.concat(predicted, axis=0)\n",
    "  predicted = tf.argmax(predicted, axis=1)\n",
    "\n",
    "  return actual, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:24:47.845921Z",
     "iopub.status.busy": "2022-12-19T02:24:47.845424Z",
     "iopub.status.idle": "2022-12-19T02:24:47.850323Z",
     "shell.execute_reply": "2022-12-19T02:24:47.849744Z"
    },
    "id": "2TmTue6THGWO"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(actual, predicted, labels, ds_type):\n",
    "  cm = tf.math.confusion_matrix(actual, predicted)\n",
    "  ax = sns.heatmap(cm, annot=True, fmt='g')\n",
    "  sns.set(rc={'figure.figsize':(12, 12)})\n",
    "  sns.set(font_scale=1.4)\n",
    "  ax.set_title('Confusion matrix of action recognition for ' + ds_type)\n",
    "  ax.set_xlabel('Predicted Action')\n",
    "  ax.set_ylabel('Actual Action')\n",
    "  plt.xticks(rotation=90)\n",
    "  plt.yticks(rotation=0)\n",
    "  ax.xaxis.set_ticklabels(labels)\n",
    "  ax.yaxis.set_ticklabels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:24:47.853341Z",
     "iopub.status.busy": "2022-12-19T02:24:47.852794Z",
     "iopub.status.idle": "2022-12-19T02:24:47.856392Z",
     "shell.execute_reply": "2022-12-19T02:24:47.855827Z"
    },
    "id": "4RK1A1C1HH6V"
   },
   "outputs": [],
   "source": [
    "fg = FrameGenerator(Path(\"./output/train\"), num_frames, training = True)\n",
    "label_names = list(fg.class_ids_for_name.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-19T02:24:47.859620Z",
     "iopub.status.busy": "2022-12-19T02:24:47.859020Z",
     "iopub.status.idle": "2022-12-19T02:25:30.159360Z",
     "shell.execute_reply": "2022-12-19T02:25:30.158717Z"
    },
    "id": "r4AFi2e5HKEO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 265s 11s/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "actual, predicted = get_actual_predicted_labels(test_ds)\n",
    "plot_confusion_matrix(actual, predicted, label_names, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddQG9sYxa1Ib"
   },
   "source": [
    "## Next steps\n",
    "\n",
    "Now that you have some familiarity with the MoViNet model and how to leverage various TensorFlow APIs (for example, for transfer learning), try using the code in this tutorial with your own dataset. The data does not have to be limited to video data. Volumetric data, such as MRI scans, can also be used with 3D CNNs. The NUSDAT and IMH datasets mentioned in [Brain MRI-based 3D Convolutional Neural Networks for Classification of Schizophrenia and Controls](https://arxiv.org/pdf/2003.08818.pdf) could be two such sources for MRI data.\n",
    "\n",
    "In particular, using the `FrameGenerator` class used in this tutorial and the other video data and classification tutorials will help you load data into your models.\n",
    "\n",
    "To learn more about working with video data in TensorFlow, check out the following tutorials:\n",
    "\n",
    "* [Load video data](https://www.tensorflow.org/tutorials/load_data/video)\n",
    "* [Build a 3D CNN model for video classification](https://www.tensorflow.org/tutorials/video/video_classification)\n",
    "* [MoViNet for streaming action recognition](https://www.tensorflow.org/hub/tutorials/movinet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "transfer_learning_with_movinet.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f76be68d9c5d6e76a66d5315d11dc6a9ea46dedf1868770abac3c9563870c381"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

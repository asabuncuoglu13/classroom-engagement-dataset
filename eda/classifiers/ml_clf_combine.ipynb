{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_levels = [-2, -1, 0, 1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_name = \"yagmur\"\n",
    "base_dir = \"../face/features/%s\" % person_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(os.path.join(base_dir, 'levels.tsv'), delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>face_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>confidence</th>\n",
       "      <th>success</th>\n",
       "      <th>gaze_0_x</th>\n",
       "      <th>gaze_0_y</th>\n",
       "      <th>gaze_0_z</th>\n",
       "      <th>gaze_1_x</th>\n",
       "      <th>gaze_1_y</th>\n",
       "      <th>...</th>\n",
       "      <th>AU12_c</th>\n",
       "      <th>AU14_c</th>\n",
       "      <th>AU15_c</th>\n",
       "      <th>AU17_c</th>\n",
       "      <th>AU20_c</th>\n",
       "      <th>AU23_c</th>\n",
       "      <th>AU25_c</th>\n",
       "      <th>AU26_c</th>\n",
       "      <th>AU28_c</th>\n",
       "      <th>AU45_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.309688</td>\n",
       "      <td>0.217516</td>\n",
       "      <td>-0.925624</td>\n",
       "      <td>-0.078749</td>\n",
       "      <td>0.124520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.744108</td>\n",
       "      <td>-0.003582</td>\n",
       "      <td>-0.668050</td>\n",
       "      <td>-0.731003</td>\n",
       "      <td>0.035917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.730967</td>\n",
       "      <td>-0.056477</td>\n",
       "      <td>-0.680072</td>\n",
       "      <td>-0.739313</td>\n",
       "      <td>-0.004669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.688489</td>\n",
       "      <td>-0.079700</td>\n",
       "      <td>-0.720854</td>\n",
       "      <td>-0.715481</td>\n",
       "      <td>0.028073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.623707</td>\n",
       "      <td>-0.017633</td>\n",
       "      <td>-0.781459</td>\n",
       "      <td>-0.733528</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame  face_id  timestamp  confidence  success  gaze_0_x  gaze_0_y  \\\n",
       "0      1        0        0.0        0.98        1  0.309688  0.217516   \n",
       "1      2        0        0.0        0.88        1 -0.744108 -0.003582   \n",
       "2      3        0        0.0        0.98        1 -0.730967 -0.056477   \n",
       "3      4        0        0.0        0.98        1 -0.688489 -0.079700   \n",
       "4      5        0        0.0        0.98        1 -0.623707 -0.017633   \n",
       "\n",
       "   gaze_0_z  gaze_1_x  gaze_1_y  ...  AU12_c  AU14_c  AU15_c  AU17_c  AU20_c  \\\n",
       "0 -0.925624 -0.078749  0.124520  ...     1.0     1.0     0.0     0.0     0.0   \n",
       "1 -0.668050 -0.731003  0.035917  ...     0.0     0.0     0.0     1.0     1.0   \n",
       "2 -0.680072 -0.739313 -0.004669  ...     0.0     1.0     0.0     1.0     0.0   \n",
       "3 -0.720854 -0.715481  0.028073  ...     0.0     1.0     0.0     0.0     0.0   \n",
       "4 -0.781459 -0.733528  0.004099  ...     0.0     1.0     1.0     0.0     0.0   \n",
       "\n",
       "   AU23_c  AU25_c  AU26_c  AU28_c  AU45_c  \n",
       "0     0.0     0.0     1.0     0.0     0.0  \n",
       "1     0.0     0.0     0.0     0.0     0.0  \n",
       "2     0.0     1.0     1.0     0.0     0.0  \n",
       "3     0.0     0.0     1.0     0.0     0.0  \n",
       "4     0.0     0.0     1.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 714 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df_face = pd.read_csv(os.path.join(base_dir, 'features.csv'))\n",
    "# Remove empty spaces in column names.\n",
    "df_face.columns = [col.replace(\" \", \"\") for col in df_face.columns]\n",
    "# Print few values of data.\n",
    "df_face.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6969 6969\n"
     ]
    }
   ],
   "source": [
    "print(len(df_face), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_conf_ind = ~np.logical_or(df_face['confidence'] < 0.5, df_face['success'] == 0)\n",
    "\n",
    "df_face = df_face.loc[high_conf_ind]\n",
    "labels = labels.loc[high_conf_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5350 5350\n"
     ]
    }
   ],
   "source": [
    "df_face = df_face.iloc[:5350,:]\n",
    "labels = labels.iloc[:5350,:]\n",
    "print(len(df_face), len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenPose Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../pose-action/features/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5350, 301) (5350, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df_pose = pd.read_csv(os.path.join(base_dir, 'pose_keypoints_with_labels.csv'))\n",
    "df_dist = pd.read_csv(os.path.join(base_dir, 'pose_distances.csv'))\n",
    "df_pose = df_pose.loc[high_conf_ind]\n",
    "df_dist = df_dist.loc[high_conf_ind]\n",
    "print(df_pose.shape, df_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feature Series Ranges\n",
    "r_au_intensities = range(df_face.columns.get_loc(\"AU01_r\"), df_face.columns.get_loc(\"AU45_r\"))\n",
    "r_au_class = range(df_face.columns.get_loc(\"AU01_c\"), df_face.columns.get_loc(\"AU45_c\"))\n",
    "r_3d_eye_landmarks = range(df_face.columns.get_loc(\"eye_lmk_X_0\"), df_face.columns.get_loc(\"eye_lmk_Z_55\"))\n",
    "r_gaze_directions = range(df_face.columns.get_loc(\"gaze_0_x\"), df_face.columns.get_loc(\"gaze_angle_y\"))\n",
    "r_pose = range(df_face.columns.get_loc(\"pose_Tx\"), df_face.columns.get_loc(\"pose_Rz\"))\n",
    "r_3d_face_landmarks = range(df_face.columns.get_loc(\"X_0\"), df_face.columns.get_loc(\"Z_67\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_au_intensities = df_face.iloc[:, r_au_intensities]\n",
    "df_au_class = df_face.iloc[:, r_au_class]\n",
    "df_3d_eye_landmarks = df_face.iloc[:, r_3d_eye_landmarks]\n",
    "df_gaze_directions = df_face.iloc[:, r_gaze_directions]\n",
    "df_pose = df_face.iloc[:, r_pose]\n",
    "df_3d_face_landmarks = df_face.iloc[:, r_3d_face_landmarks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASABUNCUOGLU13\\AppData\\Local\\Temp\\ipykernel_24380\\819994795.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_au_intensities['label'] = labels.values\n",
      "C:\\Users\\ASABUNCUOGLU13\\AppData\\Local\\Temp\\ipykernel_24380\\819994795.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_au_class['label'] = labels.values\n",
      "C:\\Users\\ASABUNCUOGLU13\\AppData\\Local\\Temp\\ipykernel_24380\\819994795.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_3d_eye_landmarks['label'] = labels.values\n",
      "C:\\Users\\ASABUNCUOGLU13\\AppData\\Local\\Temp\\ipykernel_24380\\819994795.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_gaze_directions['label'] = labels.values\n",
      "C:\\Users\\ASABUNCUOGLU13\\AppData\\Local\\Temp\\ipykernel_24380\\819994795.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pose['label'] = labels.values\n",
      "C:\\Users\\ASABUNCUOGLU13\\AppData\\Local\\Temp\\ipykernel_24380\\819994795.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_3d_face_landmarks['label'] = labels.values\n"
     ]
    }
   ],
   "source": [
    "df_au_intensities['label'] = labels.values\n",
    "df_au_class['label'] = labels.values\n",
    "df_3d_eye_landmarks['label'] = labels.values\n",
    "df_gaze_directions['label'] = labels.values\n",
    "df_pose['label'] = labels.values\n",
    "df_3d_face_landmarks['label'] = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_keypoints = [\n",
    "    {0,  \"Nose\"},\n",
    "    {1,  \"Neck\"},\n",
    "    {2,  \"RShoulder\"},\n",
    "    {3,  \"RElbow\"},\n",
    "    {4,  \"RWrist\"},\n",
    "    {5,  \"LShoulder\"},\n",
    "    {6,  \"LElbow\"},\n",
    "    {7,  \"LWrist\"},\n",
    "    {8,  \"MidHip\"},\n",
    "    {9,  \"RHip\"},\n",
    "    {10, \"RKnee\"},\n",
    "    {11, \"RAnkle\"},\n",
    "    {12, \"LHip\"},\n",
    "    {13, \"LKnee\"},\n",
    "    {14, \"LAnkle\"},\n",
    "    {15, \"REye\"},\n",
    "    {16, \"LEye\"},\n",
    "    {17, \"REar\"},\n",
    "    {18, \"LEar\"},\n",
    "    {19, \"LBigToe\"},\n",
    "    {20, \"LSmallToe\"},\n",
    "    {21, \"LHeel\"},\n",
    "    {22, \"RBigToe\"},\n",
    "    {23, \"RSmallToe\"},\n",
    "    {24, \"RHeel\"},\n",
    "    {25, \"Background\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Feature Series Ranges\n",
    "# r_p1 = range(0,74)\n",
    "# r_p2 = range(75,149)\n",
    "# r_p3 = range(150, 224)\n",
    "# r_p4 = range(225,299)\n",
    "\n",
    "# Body Points\n",
    "r_p1 = range(0,24)\n",
    "r_p2 = range(75,99)\n",
    "r_p3 = range(150, 174)\n",
    "r_p4 = range(225,249)\n",
    "\n",
    "df_p1 = df_pose.iloc[:, r_p1]\n",
    "df_p2 = df_pose.iloc[:, r_p2]\n",
    "df_p3 = df_pose.iloc[:, r_p3]\n",
    "df_p4 = df_pose.iloc[:, r_p4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASABUNCUOGLU13\\AppData\\Local\\Temp\\ipykernel_24380\\1871638433.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p1['label'] = labels.values\n",
      "C:\\Users\\ASABUNCUOGLU13\\AppData\\Local\\Temp\\ipykernel_24380\\1871638433.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p2['label'] = labels.values\n",
      "C:\\Users\\ASABUNCUOGLU13\\AppData\\Local\\Temp\\ipykernel_24380\\1871638433.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p3['label'] = labels.values\n",
      "C:\\Users\\ASABUNCUOGLU13\\AppData\\Local\\Temp\\ipykernel_24380\\1871638433.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_p4['label'] = labels.values\n"
     ]
    }
   ],
   "source": [
    "df_p1['label'] = labels.values\n",
    "df_p2['label'] = labels.values\n",
    "df_p3['label'] = labels.values\n",
    "df_p4['label'] = labels.values\n",
    "\n",
    "df_dist['label'] = labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_face_and_p4_p2_pose = pd.concat([df_3d_face_landmarks.iloc[:, :-1], df_p4.iloc[:, :-1], df_p2],axis=1)\n",
    "\n",
    "df_eye_and_p2_pose = pd.concat([df_3d_eye_landmarks.iloc[:, :-1], df_p2.iloc[:, :-1], df_pose],axis=1)\n",
    "\n",
    "df_face_and_pose_dist = pd.concat([df_3d_face_landmarks.iloc[:, :-1], df_dist],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {\n",
    "    \"Euclidian Distance and Face\": df_face_and_pose_dist,\n",
    "    \"Face - P2 and P4 Body Keypoints\": df_face_and_p4_p2_pose,\n",
    "    \"Eye and P2 Body Keypoints\": df_eye_and_p2_pose\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_names = ['LR', 'knn', 'rbf svm', 'random forest', 'boosted trees', 'mlp']\n",
    "classifiers = [LogisticRegression(random_state=42, solver=\"liblinear\"),\n",
    "                KNeighborsClassifier(n_neighbors=6),\n",
    "                SVC(gamma=2, C=1),\n",
    "                RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "                GradientBoostingClassifier(n_estimators=10, learning_rate=1, max_depth=5),\n",
    "                MLPClassifier(hidden_layer_sizes=(300, 50, 6), random_state=42, max_iter=300)]\n",
    "\n",
    "results = pd.DataFrame(columns= ['LR', 'knn', 'rbf svm', 'random forest', 'boosted trees', 'adaboost', 'title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidian Distance and Face LogisticRegression(random_state=42, solver='liblinear') 0.4895874802847817\n",
      "Euclidian Distance and Face KNeighborsClassifier(n_neighbors=6) 0.6577751796883542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASABUNCUOGLU13\\Anaconda3\\lib\\site-packages\\interpret\\glassbox\\ebm\\ebm.py:922: UserWarning: Multiclass is still experimental. Subject to change per release.\n",
      "  warn(\"Multiclass is still experimental. Subject to change per release.\")\n",
      "c:\\Users\\ASABUNCUOGLU13\\Anaconda3\\lib\\site-packages\\interpret\\glassbox\\ebm\\ebm.py:925: UserWarning: Detected multiclass problem: forcing interactions to 0\n",
      "  warn(\"Detected multiclass problem: forcing interactions to 0\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidian Distance and Face ExplainableBoostingClassifier(feature_names=['feature_0001', 'feature_0002',\n",
      "                                             'feature_0003', 'feature_0004',\n",
      "                                             'feature_0005', 'feature_0006',\n",
      "                                             'feature_0007', 'feature_0008',\n",
      "                                             'feature_0009', 'feature_0010',\n",
      "                                             'feature_0011', 'feature_0012',\n",
      "                                             'feature_0013', 'feature_0014',\n",
      "                                             'feature_0015', 'feature_0016',\n",
      "                                             'feature_0017', 'feature_0018',\n",
      "                                             'feature_0019', 'feature_0020',\n",
      "                                             'feat...\n",
      "                                             'continuous', 'continuous',\n",
      "                                             'continuous', 'continuous',\n",
      "                                             'continuous', 'continuous',\n",
      "                                             'continuous', 'continuous',\n",
      "                                             'continuous', 'continuous',\n",
      "                                             'continuous', 'continuous',\n",
      "                                             'continuous', 'continuous',\n",
      "                                             'continuous', 'continuous',\n",
      "                                             'continuous', 'continuous',\n",
      "                                             'continuous', 'continuous',\n",
      "                                             'continuous', 'continuous',\n",
      "                                             'continuous', 'continuous',\n",
      "                                             'continuous', 'continuous', ...],\n",
      "                              interactions=0) 0.572417355823516\n",
      "Euclidian Distance and Face RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10) 0.49903024250090383\n",
      "Euclidian Distance and Face GradientBoostingClassifier(learning_rate=1, max_depth=5, n_estimators=10) 0.5738484620666094\n",
      "Face - P2 and P4 Body Keypoints LogisticRegression(random_state=42, solver='liblinear') 0.536157802911001\n",
      "Face - P2 and P4 Body Keypoints KNeighborsClassifier(n_neighbors=6) 0.6191252174486336\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (4280, 250), indices imply (4280, 208)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ASABUNCUOGLU13\\Documents\\data\\engagement-analysis-experiments\\linear\\ml_clf_combine.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASABUNCUOGLU13/Documents/data/engagement-analysis-experiments/linear/ml_clf_combine.ipynb#X32sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASABUNCUOGLU13/Documents/data/engagement-analysis-experiments/linear/ml_clf_combine.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m classifiers:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ASABUNCUOGLU13/Documents/data/engagement-analysis-experiments/linear/ml_clf_combine.ipynb#X32sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASABUNCUOGLU13/Documents/data/engagement-analysis-experiments/linear/ml_clf_combine.ipynb#X32sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ASABUNCUOGLU13/Documents/data/engagement-analysis-experiments/linear/ml_clf_combine.ipynb#X32sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     res \u001b[39m=\u001b[39m f1_score(y_test, y_pred, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ASABUNCUOGLU13\\Anaconda3\\lib\\site-packages\\interpret\\glassbox\\ebm\\ebm.py:886\u001b[0m, in \u001b[0;36mBaseEBM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    876\u001b[0m \u001b[39m# Build preprocessor\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocessor_ \u001b[39m=\u001b[39m EBMPreprocessor(\n\u001b[0;32m    878\u001b[0m     feature_names\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names,\n\u001b[0;32m    879\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    884\u001b[0m     privacy_schema\u001b[39m=\u001b[39m\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprivacy_schema\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    885\u001b[0m )\n\u001b[1;32m--> 886\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocessor_\u001b[39m.\u001b[39;49mfit(X)\n\u001b[0;32m    887\u001b[0m X_orig \u001b[39m=\u001b[39m X\n\u001b[0;32m    888\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocessor_\u001b[39m.\u001b[39mtransform(X_orig)\n",
      "File \u001b[1;32mc:\\Users\\ASABUNCUOGLU13\\Anaconda3\\lib\\site-packages\\interpret\\glassbox\\ebm\\ebm.py:183\u001b[0m, in \u001b[0;36mEBMPreprocessor.fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_fitted_ \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    182\u001b[0m native \u001b[39m=\u001b[39m Native\u001b[39m.\u001b[39mget_native_singleton()\n\u001b[1;32m--> 183\u001b[0m schema \u001b[39m=\u001b[39m autogen_schema(\n\u001b[0;32m    184\u001b[0m     X, feature_names\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_names, feature_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_types\n\u001b[0;32m    185\u001b[0m )\n\u001b[0;32m    187\u001b[0m noise_scale \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m# only applicable for private binning\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mprivate\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinning:\n",
      "File \u001b[1;32mc:\\Users\\ASABUNCUOGLU13\\Anaconda3\\lib\\site-packages\\interpret\\utils\\all.py:374\u001b[0m, in \u001b[0;36mautogen_schema\u001b[1;34m(X, ordinal_max_items, feature_names, feature_types)\u001b[0m\n\u001b[0;32m    369\u001b[0m     feature_names \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfeature_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m04\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])]\n\u001b[0;32m    371\u001b[0m \u001b[39m# NOTE: Use rolled out infer_objects for old pandas.\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[39m# As used from SO:\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[39m# https://stackoverflow.com/questions/47393134/attributeerror-dataframe-object-has-no-attribute-infer-objects\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m X \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(X, columns\u001b[39m=\u001b[39;49mfeature_names)\n\u001b[0;32m    375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    376\u001b[0m     X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39minfer_objects()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    684\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    685\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    686\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    692\u001b[0m         )\n\u001b[0;32m    693\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    695\u001b[0m             data,\n\u001b[0;32m    696\u001b[0m             index,\n\u001b[0;32m    697\u001b[0m             columns,\n\u001b[0;32m    698\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    699\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    700\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    701\u001b[0m         )\n\u001b[0;32m    703\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[39m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    347\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[0;32m    348\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[0;32m    349\u001b[0m )\n\u001b[1;32m--> 351\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    353\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    355\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    420\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[0;32m    421\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[1;32m--> 422\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (4280, 250), indices imply (4280, 208)"
     ]
    }
   ],
   "source": [
    "for title in feature_sets:\n",
    "    s = [0, 0, 0, 0, 0, 0, \"title\"]\n",
    "    dfc = feature_sets[title]\n",
    "    not_zero_ind = ~(dfc == 0).all(axis=1)\n",
    "\n",
    "    dfc = dfc.loc[not_zero_ind]\n",
    "    labels = dfc['label'].loc[not_zero_ind]\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_samples = scaler.fit_transform(dfc.iloc[:,:-2])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_samples, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "    i = 0\n",
    "    for model in classifiers:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        res = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(title, model, res)\n",
    "        s[i] = res\n",
    "        i +=1\n",
    "    s[i] = title\n",
    "    results.loc[len(results.index)] = s\n",
    "    #results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('reports/f1_scores_combined_2_%s.csv' % person_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### !!!! Also test with kmeans featurizer !!! ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def test_roc(y_test, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred, pos_label=1)\n",
    "    return fpr, tpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "i = 0\n",
    "for model in classifiers: \n",
    "    scores = cross_val_score(model, scaled_samples, labels, cv=5)\n",
    "    print(\"cross val scores of scaled %s:\" % classifier_names[i], scores)\n",
    "    scores = cross_val_score(model, dfc.iloc[:,:-2], labels, cv=5)\n",
    "    print(\"cross val scores of %s:\" % classifier_names[i], scores)\n",
    "\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "for c in classifier_names:\n",
    "    fpr, tpr = test_roc(y_test.values, y_pred)\n",
    "    plt.plot(fpr, tpr, label=c)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f76be68d9c5d6e76a66d5315d11dc6a9ea46dedf1868770abac3c9563870c381"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
